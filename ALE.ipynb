{
 "metadata": {
  "name": "",
  "signature": "sha256:97ae9f55a10dea4b79489ca2e8991ee3be02b973534cbfbf1944d9eb885147d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ale_python_interface import ALEInterface\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import cv2\n",
      "import random\n",
      "from collections import deque\n",
      "import time\n",
      "import os\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/cgel/.local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
        "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ale = ALEInterface()\n",
      "viz = True\n",
      "ale.setBool('sound', False)                                                                                \n",
      "ale.setBool('display_screen', viz) \n",
      "ale.setInt(\"frame_skip\", 4)\n",
      "ale.loadROM(\"roms/Breakout.bin\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "legal_actions = ale.getMinimalActionSet()\n",
      "action_map = {}\n",
      "for i in range(len(legal_actions)):\n",
      "    action_map[i] = legal_actions[i]\n",
      "action_num = len(action_map)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Hyper Parameters:\n",
      "GAMMA = 0.99 # decay rate of past observations\n",
      "STEPS_BEFORE_TRAINING = 50000\n",
      "EXPLORE = 1000000. # frames over which to anneal epsilon\n",
      "FINAL_EPSILON = 0.1#0.001 # final value of epsilon\n",
      "INITIAL_EPSILON = 1.0#0.01 # starting value of epsilon\n",
      "REPLAY_MEMORY_SIZE = 400000 # number of previous transitions to remember\n",
      "BATCH_SIZE = 32 # size of minibatch\n",
      "PARAM_SYNC_STEPS = 10000\n",
      "INITIAL_EPSILON = 0.9\n",
      "frame_buff_size = 4\n",
      "SAVE_SUMMARY_STEPS = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replayMemory = deque()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_activation_summary(x, summaryCollection):\n",
      "    tensor_name = x.op.name                                            \n",
      "    hs = tf.histogram_summary(tensor_name + '/activations', x)\n",
      "    ss = tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
      "    tf.add_to_collection(summaryCollection, hs)\n",
      "    tf.add_to_collection(summaryCollection, ss)    \n",
      "    \n",
      "def weight_variable(shape):\n",
      "    initial = tf.truncated_normal(shape, stddev = 0.01)\n",
      "    return tf.Variable(initial)\n",
      "\n",
      "def bias_variable(shape):\n",
      "    initial = tf.constant(0.01, shape = shape)\n",
      "    return tf.Variable(initial)\n",
      "    g\n",
      "def conv2d(x, W, stride):\n",
      "    return tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = \"VALID\")\n",
      "    \n",
      "def createQNetwork(summaryCollection):\n",
      "    # network weights\n",
      "    W_conv1 = weight_variable([8,8,4,32])\n",
      "    b_conv1 = bias_variable([32])\n",
      "\n",
      "    W_conv2 = weight_variable([4,4,32,64])\n",
      "    b_conv2 = bias_variable([64])\n",
      "\n",
      "    W_conv3 = weight_variable([3,3,64,64])\n",
      "    b_conv3 = bias_variable([64])\n",
      "\n",
      "    W_fc1 = weight_variable([3136,512])\n",
      "    b_fc1 = bias_variable([512])\n",
      "\n",
      "    W_fc2 = weight_variable([512,action_num])\n",
      "    b_fc2 = bias_variable([action_num])\n",
      "\n",
      "    # input layer\n",
      "\n",
      "    input_state_placeholder = tf.placeholder(\"float\",[None,84,84,4], name=summaryCollection+\"/state_placeholder\")\n",
      "\n",
      "    # hidden layers\n",
      "    h_conv1 = tf.nn.relu(conv2d(input_state_placeholder,W_conv1,4) + b_conv1)\n",
      "    #h_pool1 = self.max_pool_2x2(h_conv1)\n",
      "\n",
      "    h_conv2 = tf.nn.relu(conv2d(h_conv1,W_conv2,2) + b_conv2)\n",
      "\n",
      "    h_conv3 = tf.nn.relu(conv2d(h_conv2,W_conv3,1) + b_conv3)\n",
      "    \n",
      "    h_conv3_shape = h_conv3.get_shape().as_list()\n",
      "    h_conv3_flat = tf.reshape(h_conv3,[-1, h_conv3_shape[1] * h_conv3_shape[2] * h_conv3_shape[3]])\n",
      "    \n",
      "    h_fc1 = tf.nn.relu(tf.matmul(h_conv3_flat,W_fc1) + b_fc1)\n",
      "\n",
      "    # Q Value layer\n",
      "    Q = tf.matmul(h_fc1,W_fc2) + b_fc2\n",
      "    build_activation_summary(Q, summaryCollection)\n",
      "    paramList = [W_conv1,b_conv1,W_conv2,b_conv2,W_conv3,b_conv3,W_fc1,b_fc1,W_fc2,b_fc2]\n",
      "    #for param in paramList:\n",
      "        #build_activation_summary(param, summaryCollection)\n",
      "        \n",
      "    return input_state_placeholder, Q, paramList"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def preprocess(new_frame, state):\n",
      "    frame = cv2.resize(new_frame, (84, 110))[26:110,:]\n",
      "    new_state = np.roll(state, 1, axis=3)\n",
      "    new_state[0,:,:,0] = frame\n",
      "    return new_state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_train_op(Y, action):\n",
      "    action_one_hot = tf.one_hot(action, action_num, 1., 0., name='action_one_hot')\n",
      "    DQN_acted = tf.reduce_sum(DQN * action_one_hot, reduction_indices=1, name='DQN_acted')\n",
      "    \n",
      "    batch_loss = tf.square(Y - DQN_acted)\n",
      "    loss = tf.reduce_mean(batch_loss)\n",
      "    tf.add_to_collection(\"DQN_summaries\", tf.scalar_summary(\"rm_average_loss\", loss))\n",
      "    tf.add_to_collection(\"DQN_summaries\", tf.scalar_summary(\"rm_loss_0\", batch_loss[0]))\n",
      "    tf.add_to_collection(\"DQN_summaries\", tf.scalar_summary(\"rm_Y_0\", Y[0]))\n",
      "    tf.add_to_collection(\"DQN_summaries\", tf.scalar_summary(\"rm_actedDQN_0\", DQN_acted[0]))\n",
      "    #tf.add_to_collection(\"DQN_summaries\", tf.scalar_summary(\"rm_maxDQN_0\", tf.reduce_max(DQN[0])))\n",
      "    return tf.train.RMSPropOptimizer(0.00025,0.99,0.0,1e-6).minimize(loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#with tf.device(\"/gpu:0\"):\n",
      "with tf.name_scope(\"DQN\"):\n",
      "    DQN_input_placeholder, DQN, DQN_params = createQNetwork(\"DQN_summaries\")\n",
      "    #the action with the highest Q\n",
      "    max_action_DQN = tf.argmax(DQN, 1)\n",
      "    #tf.scalar_summary(\"max_DQN\", max_action_DQN)\n",
      "#with tf.device(\"/gpu:1\"):\n",
      "with tf.name_scope(\"DQNTarget\"):\n",
      "    DQNT_input_placeholder, DQNT, DQNT_params = createQNetwork(\"DQNT_summaries\")\n",
      "    #the higest DQNT value\n",
      "    max_DQNT = tf.reduce_max(DQNT, 1)\n",
      "\n",
      "sync_DQNT_op = [DQNT_params[i].assign(DQN_params[i]) for i in range(len(DQN_params))]\n",
      "\n",
      "# r + Qtarget; is feeded as Y\n",
      "Y_placeholder = tf.placeholder(tf.float32, [None], name=\"Y_placeholder\")\n",
      "Action_batch = tf.placeholder(tf.int64, [None], name=\"Action_placholder\")\n",
      "train_op = build_train_op(Y_placeholder, Action_batch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "game_acc_reward = tf.placeholder(tf.float32, name=\"game_acc_reward\")\n",
      "game_acc_reward_summary_op = tf.scalar_summary(\"game_acc_reward\", game_acc_reward)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def update_params():\n",
      "    if global_step < STEPS_BEFORE_TRAINING:\n",
      "        return 0, 0\n",
      "    minibatch = random.sample(replayMemory,BATCH_SIZE)\n",
      "    state_batch = [data[0] for data in minibatch]\n",
      "    action_batch = [data[1] for data in minibatch]\n",
      "    reward_batch = [data[2] for data in minibatch]\n",
      "    nextState_batch = [data[3] for data in minibatch]\n",
      "\n",
      "    t = time.time()\n",
      "    #if global_step%SAVE_SUMMARY_STEPS == 0:\n",
      "    DQNT_max_action_batch, DQNT_summary_str = sess.run([max_DQNT, DQNT_summary_op], feed_dict={DQNT_input_placeholder:nextState_batch})\n",
      "    a = time.time() - t\n",
      "    \n",
      "    t = time.time()\n",
      "    Y = []\n",
      "    for i in range(len(minibatch)):\n",
      "        terminal = minibatch[4] == True\n",
      "        if terminal:\n",
      "            Y.append(reward_batch[i])\n",
      "        else:\n",
      "            Y.append(reward_batch[i] + GAMMA * DQNT_max_action_batch[i])\n",
      "    \n",
      "    DQN_summary_str,_ = sess.run([DQN_summary_op, train_op], feed_dict={Y_placeholder : Y, \n",
      "                                                          Action_batch : action_batch, \n",
      "                                                          DQN_input_placeholder : state_batch})\n",
      "    update_summary_str = \"\"\n",
      "    b = time.time() - t\n",
      "    \n",
      "    if global_step % SAVE_SUMMARY_STEPS == 0:\n",
      "        summary_writter.add_summary(DQNT_summary_str, global_step)\n",
      "        summary_writter.add_summary(DQN_summary_str, global_step)\n",
      "        \n",
      "    if global_step % PARAM_SYNC_STEPS == 0:\n",
      "        print(\"syncing DQNT parameters\")\n",
      "        sess.run(sync_DQNT_op)\n",
      "    return a, b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess = tf.Session(config=tf.ConfigProto(\n",
      "        allow_soft_placement=True))\n",
      "saver = tf.train.Saver()\n",
      "sess.run(tf.initialize_all_variables())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#geneate a new set of paths\n",
      "run_list = os.listdir(\"log\")\n",
      "int_run_list = [int(r) for r in run_list] + [0]\n",
      "run_name = str(max(int_run_list) + 1)\n",
      "checkpoint_path = \"checkpoint/\" + run_name + \".ckpt\"\n",
      "log_path = \"log/\"+ run_name\n",
      "print(run_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DQN_summary_op = tf.merge_summary(tf.get_collection(\"DQN_summaries\"))\n",
      "DQNT_summary_op = tf.merge_summary(tf.get_collection(\"DQNT_summaries\"))\n",
      "summary_writter = tf.train.SummaryWriter(log_path, sess.graph, flush_secs=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver.restore(sess, \"checkpoint/1.ckpt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_step = 0\n",
      "global_episode = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_epsilon():\n",
      "    if global_step < EXPLORE:\n",
      "        return INITIAL_EPSILON - ( (INITIAL_EPSILON-FINAL_EPSILON)/EXPLORE ) * global_step\n",
      "    else:\n",
      "        return FINAL_EPSILON"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FINAL_EPSILON = 0.1#0.001 # final value of epsilon"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = time.time()\n",
      "num_episodes = 1\n",
      "inie = global_episode\n",
      "for episode in range(global_episode, num_episodes + global_episode):\n",
      "    global_episode += 1\n",
      "    if episode%80 == 0:\n",
      "        percent = int(float(episode - inie)/num_episodes * 100)\n",
      "        print(\"%i%% -- epsilon:%.2f\"%(percent, get_epsilon()))\n",
      "    state = np.zeros((1, 84, 84, frame_buff_size), dtype=np.int8)\n",
      "    R = 0\n",
      "    while ale.game_over() == False:\n",
      "        raw_frame = ale.getScreenGrayscale()\n",
      "        prev_state = state\n",
      "        state = preprocess(raw_frame, state)\n",
      "        current_DQN =  sess.run(DQN, feed_dict={DQN_input_placeholder:state})[0]\n",
      "        action = np.argmax(current_DQN)\n",
      "        if np.random.uniform() < get_epsilon():\n",
      "            action = random.randint(0, action_num - 1)\n",
      "            \n",
      "        reward = ale.act(action_map[action])\n",
      "        R += reward\n",
      "        isTerminal = ale.game_over()\n",
      "        replayMemory.append((prev_state[0], action, reward, state[0], isTerminal))\n",
      "        \n",
      "        update_params()\n",
      "                \n",
      "        if len(replayMemory) > REPLAY_MEMORY_SIZE:\n",
      "            replayMemory.popleft()\n",
      "            \n",
      "        if global_step == STEPS_BEFORE_TRAINING:\n",
      "            print(\"Starting training\")\n",
      "            \n",
      "        global_step += 1\n",
      "        \n",
      "    R_str = sess.run(game_acc_reward_summary_op, feed_dict={game_acc_reward : R})\n",
      "    summary_writter.add_summary(R_str, global_episode)\n",
      "    ale.reset_game()\n",
      "print(\"==\")\n",
      "print((time.time() - t)/60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0% -- epsilon:0.90\n",
        "=="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.14170260032\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "saver.save(sess, checkpoint_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "'checkpoint/3.ckpt'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_episodes = 2\n",
      "ale.reset_game()\n",
      "for episode in range(global_episode, num_episodes + global_episode):\n",
      "    state = np.zeros((1, 84, 84, frame_buff_size), dtype=np.int8)\n",
      "    R = 0\n",
      "    while ale.game_over() == False:\n",
      "        raw_frame = ale.getScreenGrayscale()\n",
      "        prev_state = state\n",
      "        state = preprocess(raw_frame, state)\n",
      "        current_DQN =  sess.run(DQN, feed_dict={DQN_input_placeholder:state})[0]\n",
      "        action = np.argmax(current_DQN)\n",
      "        if np.random.uniform() < 0.1:\n",
      "            action = random.randint(0, action_num - 1)\n",
      "            \n",
      "        reward = ale.act(action_map[action])\n",
      "        R += reward\n",
      "        \n",
      "    ale.reset_game()\n",
      "    print(R)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def show_state(state):\n",
      "    fig = plt.figure()\n",
      "    for i in range(0, 4):\n",
      "        a=fig.add_subplot(1,4,i+1)\n",
      "        plt.axis(\"off\")\n",
      "        plt.title(str(i))\n",
      "        plt.imshow(state[:,:,i])\n",
      "\n",
      "def show_frame(frame):\n",
      "    fig = plt.figure()\n",
      "    plt.axis(\"off\")\n",
      "    plt.imshow(frame[:,:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(replayMemory)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 468,
       "text": [
        "300002"
       ]
      }
     ],
     "prompt_number": 468
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "REPLAY_MEMORY_SIZE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 469,
       "text": [
        "300000"
       ]
      }
     ],
     "prompt_number": 469
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k += 4\n",
      "mem = replayMemory[k]\n",
      "state = mem[0]\n",
      "\n",
      "#show_state(state)\n",
      "show_frame(state)\n",
      "\n",
      "action = mem[1]\n",
      "print(action)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD/CAYAAADRymv0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f638cbffb50>"
       ]
      }
     ],
     "prompt_number": 456
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 466,
       "text": [
        "dtype('int8')"
       ]
      }
     ],
     "prompt_number": 466
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(100):\n",
      "    k += 4\n",
      "    mem = replayMemory[k]\n",
      "\n",
      "    action = mem[1]\n",
      "    print(action)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n",
        "0\n",
        "3\n",
        "3\n",
        "3\n",
        "0\n",
        "3\n",
        "2\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "0\n",
        "1\n",
        "1\n",
        "3\n",
        "0\n",
        "0\n",
        "0\n",
        "3\n",
        "1\n",
        "1\n",
        "0\n",
        "0\n",
        "3\n",
        "1\n",
        "2\n",
        "2\n",
        "1\n",
        "2\n",
        "1\n",
        "2\n",
        "3\n",
        "1\n",
        "0\n",
        "1\n",
        "3\n",
        "3\n",
        "2\n",
        "3\n",
        "1\n",
        "3\n",
        "1\n",
        "2\n",
        "2\n",
        "0\n",
        "0\n",
        "0\n",
        "1\n",
        "0\n",
        "0\n",
        "0\n",
        "1\n",
        "2\n",
        "0\n",
        "0\n",
        "3\n",
        "1\n",
        "2\n",
        "3\n",
        "2\n",
        "3\n",
        "0\n",
        "0\n",
        "2\n",
        "1\n",
        "1\n",
        "1\n",
        "3\n",
        "1\n",
        "1\n",
        "0\n",
        "1\n",
        "0\n",
        "3\n",
        "1\n",
        "3\n",
        "2\n",
        "3\n",
        "1\n",
        "0\n",
        "0\n",
        "0\n",
        "3\n",
        "2\n",
        "2\n",
        "3\n",
        "0\n",
        "0\n",
        "3\n",
        "3\n",
        "3\n",
        "3\n",
        "3\n",
        "2\n",
        "3\n",
        "1\n",
        "3\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 458
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 352,
       "text": [
        "(84, 84)"
       ]
      }
     ],
     "prompt_number": 352
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show_frame(frame)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAEACAYAAAAUSCKKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny4I2gvWXtCwAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f638cbff4d0>"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#profiledt \n",
      "initial_t = time.time()\n",
      "t_DQN_forward = 0 #\n",
      "t_update = 0\n",
      "a = 0\n",
      "b = 0\n",
      "num_episodes = 5\n",
      "for episode in range(num_episodes):\n",
      "    if episode%5 == 0:\n",
      "        percent = int(float(episode)/num_episodes * 100)\n",
      "        print(\"%i%% -- epsilon:%.2f\"%(percent, get_epsilon()))\n",
      "    state = np.zeros((1, 84, 84, frame_buff_size), dtype=np.int8)\n",
      "    R = 0\n",
      "    while ale.game_over() == False:\n",
      "        raw_frame = ale.getScreenGrayscale()\n",
      "        prev_state = state\n",
      "        state = preprocess(raw_frame, state)\n",
      "        \n",
      "        t = time.time()\n",
      "        current_DQN =  sess.run(DQN, feed_dict={DQN_input_placeholder:state})[0]\n",
      "        t_DQN_forward += time.time() -t\n",
      "        \n",
      "        action = np.argmax(current_DQN)\n",
      "        if np.random.uniform() < get_epsilon():\n",
      "            action = random.randint(0, action_num - 1)\n",
      "            \n",
      "        reward = ale.act(action_map[action])\n",
      "        R += reward\n",
      "        isTerminal = ale.game_over()\n",
      "        replayMemory.append((prev_state[0], action, reward, state[0], isTerminal))\n",
      "        \n",
      "        t = time.time()\n",
      "        aa, bb = update_params()\n",
      "        a += aa\n",
      "        b += bb\n",
      "        t_update += time.time() - t\n",
      "                \n",
      "        if len(replayMemory) > REPLAY_MEMORY_SIZE:\n",
      "            replayMemory.popleft()\n",
      "            \n",
      "        if global_step == STEPS_BEFORE_TRAINING:\n",
      "            print(\"Starting training\")\n",
      "            \n",
      "        global_step += 1\n",
      "        \n",
      "    R_str = sess.run(game_acc_reward_summary_op, feed_dict={game_acc_reward : R})\n",
      "    summary_writter.add_summary(R_str, global_step)\n",
      "    ale.reset_game()\n",
      "print(\"==\")\n",
      "print((time.time() - initial_t)/60)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0% -- epsilon:0.90\n",
        "=="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.241819620132\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)\n",
      "print(\"a\", a)\n",
      "print(\"b\", b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_DQN_forward', 1.6071743965148926)\n",
        "('t_update', 10.585374593734741)\n",
        "('a', 3.200624942779541)\n",
        "('b', 7.225194454193115)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)\n",
      "print(\"a\", a)\n",
      "print(\"b\", b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_DQN_forward', 1.9984781742095947)\n",
        "('t_update', 203.87233996391296)\n",
        "('a', 101.50513792037964)\n",
        "('b', 101.08165431022644)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)\n",
      "print(\"a\", a)\n",
      "print(\"b\", b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_DQN_forward', 1.5639159679412842)\n",
        "('t_update', 10.099547386169434)\n",
        "('a', 3.1268036365509033)\n",
        "('b', 6.835911750793457)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)\n",
      "print(\"a\", a)\n",
      "print(\"b\", b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_DQN_forward', 2.1277289390563965)\n",
        "('t_update', 189.10760879516602)\n",
        "('a', 94.12078881263733)\n",
        "('b', 93.79710412025452)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_get_proc\", t_get_proc)\n",
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_get_proc', 0.8241853713989258)\n",
        "('t_DQN_forward', 2.212855815887451)\n",
        "('t_update', 229.23354172706604)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"t_get_proc\", t_get_proc)\n",
      "print(\"t_DQN_forward\", t_DQN_forward)\n",
      "print(\"t_update\", t_update)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('t_get_proc', 0.8241853713989258)\n",
        "('t_DQN_forward', 2.212855815887451)\n",
        "('t_update', 229.23354172706604)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global_step"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "18868"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "STEPS_BEFORE_TRAINING"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "1000"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imgs = transition_batch[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state = imgs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PIL import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "1466209213.747968"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frame = ale.getScreenGrayscale()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state = np.zeros((1, 84, 84, frame_buff_size), dtype=np.float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_state = preprocess(frame, state)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(84, 84)\n"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state = new_state"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(4):\n",
      "    print(state[:,:,i].max())\n",
      "    Image.fromarray(state[0,:,:,i]).show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "142.0\n",
        "142.0\n",
        "142.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "142.0\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(state[:,:,:,tt].max())\n",
      "Image.fromarray(state[0,:,:,tt]).show()\n",
      "tt += 1\n",
      "print(state[0,:,:,tt].max())\n",
      "print(tt)\n",
      "if tt == 3:\n",
      "    print(\"top\")\n",
      "    tt = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "148.0\n",
        "0.0\n",
        "1\n"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state[0,:,:,1].max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 136,
       "text": [
        "0.0"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tt = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_state = np.roll(state, 1, axis=3)\n",
      "print(new_state.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1, 84, 84, 4)\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\t\tif self.epsilon > FINAL_EPSILON and self.timeStep > OBSERVE:\n",
      "\t\t\tself.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON)/EXPLORE\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(threshold=np.nan)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.Variable([[1,2],[3,4],[5,6]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind = tf.Variable([1,0,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "range_ind = tf.concat(1, [tf.expand_dims(tf.range(0,tf.shape(ind)[0]), 1), tf.expand_dims(ind, 1)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess.run(range_ind)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "array([[0, 1],\n",
        "       [1, 0],\n",
        "       [2, 1]], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess.run(tf.gather_nd(x, range_ind))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 96,
       "text": [
        "array([2, 3, 6], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}